{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b57e21f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/dask/dataframe/__init__.py:31: FutureWarning: The legacy Dask DataFrame implementation is deprecated and will be removed in a future version. Set the configuration option `dataframe.query-planning` to `True` or None to enable the new Dask Dataframe implementation and silence this warning.\n",
      "  warnings.warn(\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/spatialdata/_core/query/relational_query.py:504: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "  left = partial(_left_join_spatialelement_table)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/spatialdata/_core/query/relational_query.py:505: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "  left_exclusive = partial(_left_exclusive_join_spatialelement_table)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/spatialdata/_core/query/relational_query.py:506: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "  inner = partial(_inner_join_spatialelement_table)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/spatialdata/_core/query/relational_query.py:507: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "  right = partial(_right_join_spatialelement_table)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/spatialdata/_core/query/relational_query.py:508: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in enum.member() if you want to preserve the old behavior\n",
      "  right_exclusive = partial(_right_exclusive_join_spatialelement_table)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/numba/core/decorators.py:246: RuntimeWarning: nopython is set for njit and is ignored\n",
      "  warnings.warn('nopython is set for njit and is ignored', RuntimeWarning)\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/anndata/utils.py:434: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "\n",
    "dask.config.set({\"dataframe.query-planning\": False})\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score\n",
    "from scib_metrics.benchmark import Benchmarker, BioConservation, BatchCorrection\n",
    "from itertools import product\n",
    "\n",
    "import sys\n",
    "sys.path.extend(['../../scripts','../../scripts/xenium'])\n",
    "import readwrite\n",
    "import preprocessing\n",
    "\n",
    "cfg = readwrite.config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ddf5de",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f3b357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "cell_type_annotation_dir = Path(cfg['xenium_cell_type_annotation_dir'])\n",
    "xenium_processed_data_dir = Path(cfg['xenium_processed_data_dir'])\n",
    "xenium_std_seurat_analysis_dir = Path(cfg['xenium_std_seurat_analysis_dir'])\n",
    "results_dir = Path(cfg['results_dir'])\n",
    "seurat_to_h5_dir = results_dir / 'seurat_to_h5'\n",
    "\n",
    "normalisation = 'lognorm'\n",
    "layer = 'data'\n",
    "reference = 'matched_reference_combo'\n",
    "method = 'rctd_class_aware'\n",
    "level = 'Level2.1'\n",
    "n_comps = 50\n",
    "max_n_cells = 100_000\n",
    "singlets = False\n",
    "\n",
    "# qc params\n",
    "min_counts = 10\n",
    "min_features = 5\n",
    "max_counts = float(\"inf\")\n",
    "max_features = float(\"inf\")\n",
    "min_cells = 5\n",
    "\n",
    "# common genes and samples to use for NSCLC\n",
    "nsclc_shared_genes = pd.read_csv(cfg['markers_dir']+'Xenium_NSCLC_5k_lung_chromium_common_genes.csv')['gene'].tolist()\n",
    "nsclc_shared_samples = ['0PSV','1G73']\n",
    "\n",
    "# fixed params\n",
    "OBSM_KEY = \"X_pca\"\n",
    "CT_KEY = (reference, method, level)\n",
    "BATCH_KEY = \"batch_key\"\n",
    "annotation_normalisation = \"lognorm\"  # fix this for now, even for sctransfrom\n",
    "exclude_cell_type_containing = \"malignant\"\n",
    "\n",
    "# set up metrics\n",
    "batchcor = BatchCorrection(\n",
    "    silhouette_batch=True,\n",
    "    ilisi_knn=True,\n",
    "    kbet_per_label=True,\n",
    "    graph_connectivity=True,\n",
    "    pcr_comparison=True,\n",
    ")\n",
    "\n",
    "biocons = BioConservation(\n",
    "    isolated_labels=True,\n",
    "    nmi_ari_cluster_labels_leiden=True,\n",
    "    nmi_ari_cluster_labels_kmeans=True,\n",
    "    silhouette_label=True,\n",
    "    clisi_knn=True,\n",
    ")\n",
    "\n",
    "CONDITIONS_REFS = {\n",
    "    \"breast\": \"matched_combo_standard_breast_specific\",\n",
    "    \"NSCLC\": \"matched_combo_standard_lung_specific\",\n",
    "}\n",
    "\n",
    "\n",
    "# params product to compute metrics for\n",
    "share_flags = ['all','shared']\n",
    "segmentations = ['10x_0um', '10x_5um','10x_mm_5um']\n",
    "panels = ['breast','lung','chuvio','5k']\n",
    "\n",
    "gene_panels = {}\n",
    "loop_params_xenium = []\n",
    "for segmentation, panel, share_flag in product(segmentations,panels,share_flags):\n",
    "    if segmentation == \"10x_mm_5um\" and panel != \"5k\":\n",
    "        # 10x_mm_5um only available for 5k\n",
    "        continue\n",
    "\n",
    "    if panel == 'breast':\n",
    "        condition = 'breast'\n",
    "        if share_flag == 'shared':\n",
    "            continue\n",
    "    elif panel in ['5k', 'lung','chuvio']:\n",
    "        condition = 'NSCLC'\n",
    "        if panel =='chuvio' and share_flag == 'shared':\n",
    "            continue\n",
    "\n",
    "    # get gene panel info from first sample\n",
    "    panel_path = Path(cfg['xenium_processed_data_dir'] + f'10x_5um/{condition}/{panel}')\n",
    "    donor = list(panel_path.iterdir())[0]\n",
    "    sample = list(donor.iterdir())[0]\n",
    "    df = readwrite.get_gene_panel_info(sample / 'normalised_results/outs/gene_panel.json')\n",
    "    gene_panels[panel] = df[df['id'].notna()]['name'].tolist()\n",
    "\n",
    "    loop_params_xenium.append([segmentation, condition, panel, share_flag, share_flag])\n",
    "loop_params_xenium = pd.DataFrame(loop_params_xenium, columns=['segmentation','condition', 'panel', 'genes', 'samples'])\n",
    "\n",
    "# scrna params product to compute metrics for\n",
    "conditions = ['breast','NSCLC']\n",
    "gene_sets = ['hvg','shared'] + panels\n",
    "loop_params_scrna = []\n",
    "for condition, gene_set in product(conditions,gene_sets):\n",
    "    if condition == 'breast' and gene_set not in ['hvg','breast']:\n",
    "        continue\n",
    "    if condition == 'NSCLC' and gene_set == 'breast':\n",
    "        continue\n",
    "    if gene_set =='shared': \n",
    "        sample_set = 'shared'\n",
    "    else:\n",
    "        sample_set = 'all'\n",
    "    loop_params_scrna.append([condition, gene_set, sample_set])\n",
    "loop_params_scrna = pd.DataFrame(loop_params_scrna, columns=['condition', 'genes', 'samples'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb51f8a",
   "metadata": {},
   "source": [
    "## Compute metrics Xenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9193df71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10x_0um breast breast all all\n",
      "\n",
      "Found file, skipping\n",
      "10x_0um NSCLC lung all all\n",
      "\n",
      "Found file, skipping\n",
      "10x_0um NSCLC lung shared shared\n",
      "Reading samples\n",
      "\u001b[34mINFO    \u001b[0m reading                                                                                                   \n",
      "         \u001b[35m/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/data/xenium/processed/segmentation/10x_0um/NSCLC/lu\u001b[0m\n",
      "         \u001b[35mng/0PSV/0PSV/normalised_results/outs/\u001b[0m\u001b[95mcell_feature_matrix.h5\u001b[0m                                               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/spatialdata/_core/spatialdata.py:158: UserWarning: The table is annotating 'cell_labels', which is not present in the SpatialData object.\n",
      "  self.validate_table_in_spatialdata(v)\n",
      "/tmp/ipykernel_1890867/1764984870.py:55: ImplicitModificationWarning: Setting element `.layers['X_normalised']` of view, initializing view as actual.\n",
      "  ads[k].layers[\"X_normalised\"] = X_normalised\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m reading                                                                                                   \n",
      "         \u001b[35m/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/data/xenium/processed/segmentation/10x_0um/NSCLC/lu\u001b[0m\n",
      "         \u001b[35mng/1G73/1G73/normalised_results/outs/\u001b[0m\u001b[95mcell_feature_matrix.h5\u001b[0m                                               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/spatialdata/_core/spatialdata.py:158: UserWarning: The table is annotating 'cell_labels', which is not present in the SpatialData object.\n",
      "  self.validate_table_in_spatialdata(v)\n",
      "/tmp/ipykernel_1890867/1764984870.py:55: ImplicitModificationWarning: Setting element `.layers['X_normalised']` of view, initializing view as actual.\n",
      "  ads[k].layers[\"X_normalised\"] = X_normalised\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating\n",
      "Done\n",
      "Subsetting\n",
      "Found 194 out of 194 genes.\n",
      "Removed 24311  cells...\n",
      "Removed 0  genes...\n",
      "GPU not available. Switching to CPU backend...\n",
      "Using 2 samples and 194 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing neighbors: 100%|██████████| 1/1 [00:20<00:00, 20.68s/it]\n",
      "Embeddings:   0%|\u001b[32m          \u001b[0m| 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m \u001b[1;36m17\u001b[0m clusters consist of a single batch or are too small. Skip.                                             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/scib_metrics/metrics/_kbet.py:212: RuntimeWarning: Mean of empty slice\n",
      "  final_score = np.nanmean(kbet_scores[\"kBET\"])\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/scib_metrics/metrics/_graph_connectivity.py:32: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(comps)\n",
      "Embeddings: 100%|\u001b[32m██████████\u001b[0m| 1/1 [08:09<00:00, 489.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10x_0um NSCLC chuvio all all\n",
      "\n",
      "Found file, skipping\n",
      "10x_0um NSCLC 5k all all\n",
      "\n",
      "Found file, skipping\n",
      "10x_0um NSCLC 5k shared shared\n",
      "\n",
      "Found file, skipping\n",
      "10x_5um breast breast all all\n",
      "\n",
      "Found file, skipping\n",
      "10x_5um NSCLC lung all all\n",
      "\n",
      "Found file, skipping\n",
      "10x_5um NSCLC lung shared shared\n",
      "\n",
      "Found file, skipping\n",
      "10x_5um NSCLC chuvio all all\n",
      "\n",
      "Found file, skipping\n",
      "10x_5um NSCLC 5k all all\n",
      "\n",
      "Found file, skipping\n",
      "10x_5um NSCLC 5k shared shared\n",
      "\n",
      "Found file, skipping\n",
      "10x_mm_5um NSCLC 5k all all\n",
      "\n",
      "Found file, skipping\n",
      "10x_mm_5um NSCLC 5k shared shared\n",
      "\n",
      "Found file, skipping\n"
     ]
    }
   ],
   "source": [
    "for segmentation, condition, panel_name, genes, samples in loop_params_xenium.values:\n",
    "    print(segmentation, condition, panel_name, genes, samples)\n",
    "\n",
    "    out_file =  results_dir / f'revision_separability_metrics/scib_metrics_{segmentation}_{condition}_{panel_name}_{normalisation}_{layer}_{genes=}_{samples=}.parquet'\n",
    "    if out_file.exists():\n",
    "        print(\"\\nFound file, skipping\")\n",
    "        continue\n",
    "\n",
    "    if segmentation == \"10x_mm_5um\" and panel_name != \"5k\":\n",
    "        # 10x_mm_5um only available for 5k\n",
    "        continue\n",
    "    \n",
    "    if panel_name == 'breast':\n",
    "        condition = 'breast'\n",
    "    elif panel_name in ('5k', 'lung'):\n",
    "        condition = 'NSCLC'\n",
    "        \n",
    "    panel = xenium_std_seurat_analysis_dir / f\"{segmentation}/{condition}/{panel_name}\"\n",
    "    \n",
    "    # read xenium samples\n",
    "    print(\"Reading samples\")\n",
    "    ads = {}\n",
    "    for donor in (donors := panel.iterdir()):\n",
    "        for sample in (samples_ := donor.iterdir()):\n",
    "            if samples == 'shared' and sample.stem not in nsclc_shared_samples:\n",
    "                continue\n",
    "\n",
    "                print(donor.stem, sample.stem)\n",
    "\n",
    "            if segmentation == \"proseg_expected\":\n",
    "                k = (\"proseg\", condition, panel.stem, donor.stem, sample.stem)\n",
    "                name_sample = \"/\".join(k)\n",
    "                sample_dir = xenium_processed_data_dir / f\"{name_sample}/raw_results\"\n",
    "            else:\n",
    "                k = (segmentation.replace(\"proseg_mode\", \"proseg\"), condition, panel.stem, donor.stem, sample.stem)\n",
    "                name_sample = \"/\".join(k)\n",
    "                sample_dir = xenium_processed_data_dir / f\"{name_sample}/normalised_results/outs\"\n",
    "\n",
    "            sample_normalised_counts_path = sample / f\"{normalisation}/normalised_counts/{layer}.parquet\"\n",
    "            sample_idx_path = sample / f\"{normalisation}/normalised_counts/cells.parquet\"\n",
    "\n",
    "            # read normalised data\n",
    "            X_normalised = pd.read_parquet(sample_normalised_counts_path)\n",
    "            X_normalised.index = pd.read_parquet(sample_idx_path).iloc[:, 0]\n",
    "            X_normalised.columns = X_normalised.columns.str.replace(\".\", \"-\")  # undo seurat renaming\n",
    "\n",
    "            if genes == 'shared':\n",
    "                # load raw data to reapply lower bounds QC filters\n",
    "                ads[k] = readwrite.read_xenium_sample(sample_dir, anndata=True)\n",
    "                if segmentation == \"proseg_expected\":\n",
    "                    ads[k].obs_names = \"proseg-\" + ads[k].obs_names.astype(str)\n",
    "\n",
    "                # filter cells\n",
    "                ads[k] = ads[k][X_normalised.index, X_normalised.columns]\n",
    "                ads[k].layers[\"X_normalised\"] = X_normalised\n",
    "                if layer != \"scale_data\":  # no need to sparsify scale_data which is dense\n",
    "                    ads[k].layers[\"X_normalised\"] = scipy.sparse.csr_matrix(ads[k].layers[\"X_normalised\"])\n",
    "            else:\n",
    "                ads[k] = sc.AnnData(X_normalised)\n",
    "                if layer != \"scale_data\":  # no need to sparsify scale_data which is dense\n",
    "                    ads[k].X = scipy.sparse.csr_matrix(ads[k].X)\n",
    "\n",
    "            # read cell type annotation\n",
    "            sample_annotation_dir = cell_type_annotation_dir / f\"{name_sample}/{annotation_normalisation}/reference_based\"\n",
    "            annot_file = sample_annotation_dir / f\"{reference}/{method}/{level}/single_cell/labels.parquet\"\n",
    "            ads[k].obs[CT_KEY] = pd.read_parquet(annot_file).set_index(\"cell_id\").iloc[:, 0]\n",
    "\n",
    "            if singlets:\n",
    "                # read spot class\n",
    "                spot_class_file = (\n",
    "                    sample_annotation_dir / f\"{reference}/{method}/{level}/single_cell/output/results_df.parquet\"\n",
    "                )\n",
    "\n",
    "                ads[k].obs[\"spot_class\"] = pd.read_parquet(spot_class_file, columns=[\"cell_id\", \"spot_class\"]).set_index(\n",
    "                    \"cell_id\"\n",
    "                )\n",
    "                ads[k] = ads[k][ads[k].obs[\"spot_class\"] == \"singlet\"]\n",
    "\n",
    "\n",
    "    print(\"Concatenating\")\n",
    "    # concatenate\n",
    "    xenium_levels = [\"segmentation\", \"condition\", \"panel\", \"donor\", \"sample\"]\n",
    "    for k in ads.keys():\n",
    "        for i, lvl in enumerate(xenium_levels):\n",
    "            ads[k].obs[lvl] = k[i]\n",
    "    ad_merge = sc.concat(ads)\n",
    "    ad_merge.obs[BATCH_KEY] = ad_merge.obs[xenium_levels].agg(\"_\".join, axis=1)\n",
    "    print(\"Done\")\n",
    "\n",
    "    # subset to genes\n",
    "    if genes == 'shared':\n",
    "        print(\"Subsetting\")\n",
    "\n",
    "        genes_found = [\n",
    "            g\n",
    "            for g in ad_merge.var_names\n",
    "            if (g in nsclc_shared_genes) or (g.replace(\".\", \"-\") in nsclc_shared_genes)  # possible seurat renaming\n",
    "        ]\n",
    "\n",
    "        print(f\"Found {len(genes_found)} out of {len(nsclc_shared_genes)} genes.\")\n",
    "        ad_merge = ad_merge[:, genes_found].copy()\n",
    "        # reapply QC to subset of genes\n",
    "        preprocessing.preprocess(\n",
    "            ad_merge,\n",
    "            min_counts=min_counts,\n",
    "            min_genes=min_features,\n",
    "            max_counts=max_counts,\n",
    "            max_genes=max_features,\n",
    "            min_cells=min_cells,\n",
    "            save_raw=False,\n",
    "        )\n",
    "        # replace X\n",
    "        ad_merge.X = ad_merge.layers[\"X_normalised\"]\n",
    "\n",
    "    # remove NaN  and exclude_cell_type_containing annotations\n",
    "    ad_merge = ad_merge[ad_merge.obs[CT_KEY].notna()]\n",
    "    ad_merge = ad_merge[~ad_merge.obs[CT_KEY].str.contains(exclude_cell_type_containing)].copy()\n",
    "\n",
    "    print('Using',ad_merge.obs['sample'].nunique(),'samples and',ad_merge.n_vars,'genes')\n",
    "\n",
    "    # subsample to reasonable size\n",
    "    if len(ad_merge) > max_n_cells:\n",
    "        sc.pp.subsample(ad_merge, n_obs=max_n_cells)\n",
    "\n",
    "    # compute pca\n",
    "    sc.tl.pca(ad_merge, n_comps=n_comps)\n",
    "\n",
    "    # benchmark\n",
    "    bm = Benchmarker(\n",
    "        ad_merge,\n",
    "        batch_key=BATCH_KEY,\n",
    "        label_key=CT_KEY,\n",
    "        embedding_obsm_keys=[OBSM_KEY],\n",
    "        pre_integrated_embedding_obsm_key=OBSM_KEY,\n",
    "        bio_conservation_metrics=biocons,\n",
    "        batch_correction_metrics=batchcor,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    bm.benchmark()\n",
    "\n",
    "    df_metrics = bm.get_results(min_max_scale=False).iloc[[0]]\n",
    "\n",
    "    # df_metrics['sklearn_silhouette'] = silhouette_score(ad_merge.obsm[OBSM_KEY], ad_merge.obs[CT_KEY], metric='euclidean', random_state=0)\n",
    "    df_metrics['calinski_harabasz'] = calinski_harabasz_score(ad_merge.obsm[OBSM_KEY], ad_merge.obs[CT_KEY])\n",
    "    df_metrics['davies_bouldin'] = davies_bouldin_score(ad_merge.obsm[OBSM_KEY], ad_merge.obs[CT_KEY])\n",
    "\n",
    "    out_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_metrics.to_parquet(out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcea6ab",
   "metadata": {},
   "source": [
    "## Compute metrics scRNAseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7bcf9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched_combo_standard_breast_specific breast hvg all\n",
      "Reading samples\n",
      "Using 10 samples and 3000 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing neighbors: 100%|██████████| 1/1 [00:07<00:00,  7.41s/it]\n",
      "Embeddings:   0%|\u001b[32m          \u001b[0m| 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m \u001b[1;36m16\u001b[0m clusters consist of a single batch or are too small. Skip.                                             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/scib_metrics/metrics/_kbet.py:212: RuntimeWarning: Mean of empty slice\n",
      "  final_score = np.nanmean(kbet_scores[\"kBET\"])\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/scib_metrics/metrics/_graph_connectivity.py:32: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(comps)\n",
      "Embeddings: 100%|\u001b[32m██████████\u001b[0m| 1/1 [01:17<00:00, 77.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched_combo_standard_breast_specific breast breast all\n",
      "Reading samples\n",
      "Subsetting\n",
      "Found 277 out of 280 genes.\n",
      "Removed 3710  cells...\n",
      "Removed 2  genes...\n",
      "GPU not available. Switching to CPU backend...\n",
      "Using 10 samples and 277 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing neighbors: 100%|██████████| 1/1 [00:06<00:00,  6.87s/it]\n",
      "Embeddings:   0%|\u001b[32m          \u001b[0m| 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m \u001b[1;36m16\u001b[0m clusters consist of a single batch or are too small. Skip.                                             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/scib_metrics/metrics/_kbet.py:212: RuntimeWarning: Mean of empty slice\n",
      "  final_score = np.nanmean(kbet_scores[\"kBET\"])\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/scib_metrics/metrics/_graph_connectivity.py:32: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(comps)\n",
      "Embeddings: 100%|\u001b[32m██████████\u001b[0m| 1/1 [01:05<00:00, 65.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched_combo_standard_lung_specific NSCLC hvg all\n",
      "Reading samples\n",
      "Using 10 samples and 3000 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing neighbors: 100%|██████████| 1/1 [00:08<00:00,  8.88s/it]\n",
      "Embeddings:   0%|\u001b[32m          \u001b[0m| 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m \u001b[1;36m17\u001b[0m clusters consist of a single batch or are too small. Skip.                                             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/scib_metrics/metrics/_kbet.py:212: RuntimeWarning: Mean of empty slice\n",
      "  final_score = np.nanmean(kbet_scores[\"kBET\"])\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/scib_metrics/metrics/_graph_connectivity.py:32: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(comps)\n",
      "Embeddings: 100%|\u001b[32m██████████\u001b[0m| 1/1 [01:19<00:00, 79.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched_combo_standard_lung_specific NSCLC shared shared\n",
      "Reading samples\n",
      "Subsetting\n",
      "Found 194 out of 194 genes.\n",
      "Removed 4252  cells...\n",
      "Removed 1  genes...\n",
      "GPU not available. Switching to CPU backend...\n",
      "Using 2 samples and 194 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing neighbors: 100%|██████████| 1/1 [00:02<00:00,  3.00s/it]\n",
      "Embeddings:   0%|\u001b[32m          \u001b[0m| 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m \u001b[1;36m17\u001b[0m clusters consist of a single batch or are too small. Skip.                                             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/scib_metrics/metrics/_kbet.py:212: RuntimeWarning: Mean of empty slice\n",
      "  final_score = np.nanmean(kbet_scores[\"kBET\"])\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/scib_metrics/metrics/_graph_connectivity.py:32: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(comps)\n",
      "Embeddings: 100%|\u001b[32m██████████\u001b[0m| 1/1 [00:20<00:00, 20.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched_combo_standard_lung_specific NSCLC lung all\n",
      "Reading samples\n",
      "Subsetting\n",
      "Found 284 out of 289 genes.\n",
      "Removed 8283  cells...\n",
      "Removed 1  genes...\n",
      "GPU not available. Switching to CPU backend...\n",
      "Using 10 samples and 284 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing neighbors: 100%|██████████| 1/1 [00:06<00:00,  6.36s/it]\n",
      "Embeddings:   0%|\u001b[32m          \u001b[0m| 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m \u001b[1;36m17\u001b[0m clusters consist of a single batch or are too small. Skip.                                             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/scib_metrics/metrics/_kbet.py:212: RuntimeWarning: Mean of empty slice\n",
      "  final_score = np.nanmean(kbet_scores[\"kBET\"])\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/scib_metrics/metrics/_graph_connectivity.py:32: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(comps)\n",
      "Embeddings: 100%|\u001b[32m██████████\u001b[0m| 1/1 [00:59<00:00, 59.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched_combo_standard_lung_specific NSCLC chuvio all\n",
      "Reading samples\n",
      "Subsetting\n",
      "Found 318 out of 340 genes.\n",
      "Removed 1509  cells...\n",
      "Removed 7  genes...\n",
      "GPU not available. Switching to CPU backend...\n",
      "Using 10 samples and 318 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing neighbors: 100%|██████████| 1/1 [00:08<00:00,  8.26s/it]\n",
      "Embeddings:   0%|\u001b[32m          \u001b[0m| 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m \u001b[1;36m17\u001b[0m clusters consist of a single batch or are too small. Skip.                                             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/scib_metrics/metrics/_kbet.py:212: RuntimeWarning: Mean of empty slice\n",
      "  final_score = np.nanmean(kbet_scores[\"kBET\"])\n",
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/scib_metrics/metrics/_graph_connectivity.py:32: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(comps)\n",
      "Embeddings: 100%|\u001b[32m██████████\u001b[0m| 1/1 [01:18<00:00, 78.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched_combo_standard_lung_specific NSCLC 5k all\n",
      "Reading samples\n",
      "Subsetting\n",
      "Found 4827 out of 5001 genes.\n",
      "Removed 0  cells...\n",
      "Removed 164  genes...\n",
      "GPU not available. Switching to CPU backend...\n",
      "Using 10 samples and 4827 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing neighbors: 100%|██████████| 1/1 [00:07<00:00,  7.27s/it]\n",
      "Embeddings:   0%|\u001b[32m          \u001b[0m| 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m \u001b[1;36m17\u001b[0m clusters consist of a single batch or are too small. Skip.                                             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/scib_metrics/metrics/_kbet.py:212: RuntimeWarning: Mean of empty slice\n",
      "  final_score = np.nanmean(kbet_scores[\"kBET\"])/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/jbac/miniforge3/envs/spatial/lib/python3.13/site-packages/scib_metrics/metrics/_graph_connectivity.py:32: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  tab = pd.value_counts(comps)\n",
      "Embeddings: 100%|\u001b[32m██████████\u001b[0m| 1/1 [01:17<00:00, 77.54s/it]\n"
     ]
    }
   ],
   "source": [
    "assay = 'RNA'\n",
    "load_scrna_normalisation = 'counts' # lognorm again to be sure, data slot can be unnormalized\n",
    "\n",
    "for condition_name, genes, samples in loop_params_scrna.values:\n",
    "\n",
    "    reference_name = CONDITIONS_REFS[condition_name]\n",
    "    reference_path = seurat_to_h5_dir / reference_name\n",
    "    print(reference_name, condition_name, genes, samples)\n",
    "\n",
    "    print(\"Reading samples\")\n",
    "    ad_merge = sc.read_10x_h5(reference_path / f\"{assay}_{load_scrna_normalisation}.h5\")\n",
    "    ad_merge.obs = pd.read_parquet(reference_path / 'metadata.parquet').set_index('cell_id')\n",
    "    \n",
    "    # subset to shared samples\n",
    "    if samples == 'shared':\n",
    "        ad_merge = ad_merge[ad_merge.obs['donor'].isin(nsclc_shared_samples)].copy()\n",
    "\n",
    "    # subset to genes\n",
    "    if genes != 'hvg':\n",
    "        print(\"Subsetting\")\n",
    "        if genes == 'shared':\n",
    "            gene_subset = nsclc_shared_genes\n",
    "        else:\n",
    "            gene_subset = gene_panels[genes]\n",
    "\n",
    "        genes_found = [\n",
    "            g\n",
    "            for g in ad_merge.var_names\n",
    "            if (g in gene_subset) or (g.replace(\".\", \"-\") in gene_subset)  # possible seurat renaming\n",
    "        ]\n",
    "\n",
    "        print(f\"Found {len(genes_found)} out of {len(gene_subset)} genes.\")\n",
    "\n",
    "        # read raw counts to reapply QC\n",
    "        ad_merge_raw_counts = sc.read_10x_h5(reference_path / f\"{assay}_counts.h5\")\n",
    "        ad_merge_raw_counts = ad_merge[:, genes_found].copy()\n",
    "\n",
    "        # reapply QC to subset of genes\n",
    "        preprocessing.preprocess(\n",
    "            ad_merge_raw_counts,\n",
    "            min_counts=min_counts,\n",
    "            min_genes=min_features,\n",
    "            max_counts=max_counts,\n",
    "            max_genes=max_features,\n",
    "            min_cells=min_cells,\n",
    "            save_raw=False,\n",
    "        )\n",
    "        # subset\n",
    "        ad_merge = ad_merge[ad_merge_raw_counts.obs_names, genes_found].copy()\n",
    "\n",
    "    else:\n",
    "        sc.pp.highly_variable_genes(ad_merge, n_top_genes=3000,flavor='seurat_v3_paper',subset=True)\n",
    "\n",
    "    if \"counts\" in load_scrna_normalisation:\n",
    "        sc.pp.normalize_total(ad_merge)\n",
    "        sc.pp.log1p(ad_merge)\n",
    "        scrna_normalisation = \"lognorm\"\n",
    "\n",
    "    # remove NaN  and exclude_cell_type_containing annotations\n",
    "    ad_merge = ad_merge[ad_merge.obs[level].notna()]\n",
    "    ad_merge = ad_merge[~ad_merge.obs[level].str.contains(exclude_cell_type_containing)].copy()\n",
    "    ad_merge.obs[BATCH_KEY] = ad_merge.obs['donor']\n",
    "\n",
    "\n",
    "    print('Using',ad_merge.obs['donor'].nunique(),'samples and',ad_merge.n_vars,'genes')\n",
    "\n",
    "    # subsample to reasonable size\n",
    "    if len(ad_merge) > max_n_cells:\n",
    "        sc.pp.subsample(ad_merge, n_obs=max_n_cells)\n",
    "\n",
    "    # compute pca\n",
    "    sc.tl.pca(ad_merge, n_comps=n_comps)\n",
    "\n",
    "    # benchmark\n",
    "    bm = Benchmarker(\n",
    "        ad_merge,\n",
    "        batch_key=BATCH_KEY,\n",
    "        label_key=level,\n",
    "        embedding_obsm_keys=[OBSM_KEY],\n",
    "        pre_integrated_embedding_obsm_key=OBSM_KEY,\n",
    "        bio_conservation_metrics=biocons,\n",
    "        batch_correction_metrics=batchcor,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    bm.benchmark()\n",
    "\n",
    "    df_metrics = bm.get_results(min_max_scale=False).iloc[[0]]\n",
    "\n",
    "    # df_metrics['sklearn_silhouette'] = silhouette_score(ad_merge.obsm[OBSM_KEY], ad_merge.obs[CT_KEY], metric='euclidean', random_state=0)\n",
    "    df_metrics['calinski_harabasz'] = calinski_harabasz_score(ad_merge.obsm[OBSM_KEY], ad_merge.obs[level])\n",
    "    df_metrics['davies_bouldin'] = davies_bouldin_score(ad_merge.obsm[OBSM_KEY], ad_merge.obs[level])\n",
    "\n",
    "    out_file =  results_dir / f'revision_separability_metrics/scib_metrics_{reference_name}_{condition_name}_{scrna_normalisation}_{genes=}_{samples=}.parquet'\n",
    "    out_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_metrics.to_parquet(out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fd3ddc",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69f3f5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('breast', 'hvg', 'all')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_name, genes, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d67a6732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath(\"/work/PRTNR/CHUV/DIR/rgottar1/spatial/env/xenium_paper/results/revision_separability_metrics/scib_metrics_matched_combo_standard_lung_specific_breast_lognorm_genes='hvg'_samples='all'.parquet\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b58c2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = {}\n",
    "\n",
    "for segmentation, condition, panel_name, genes, samples in loop_params_xenium.values:\n",
    "    out_file =  results_dir / f'revision_separability_metrics/scib_metrics_{segmentation}_{condition}_{panel_name}_{normalisation}_{layer}_{genes=}_{samples=}.parquet'\n",
    "    df_metrics['xenium', segmentation, condition, panel_name, genes, samples] = pd.read_parquet(out_file)\n",
    "for condition, genes, samples in loop_params_scrna.values:\n",
    "    reference_name = CONDITIONS_REFS[condition]\n",
    "    out_file =  results_dir / f'revision_separability_metrics/scib_metrics_{reference_name}_{condition}_{scrna_normalisation}_{genes=}_{samples=}.parquet'\n",
    "    df_metrics['chromium', reference_name, condition_name, 'chromium', genes, samples] = pd.read_parquet(out_file)\n",
    "df_metrics = pd.concat(df_metrics).reset_index()\n",
    "\n",
    "cols = ['technology', 'segmentation/chromium_reference', 'condition', 'panel', 'genes', 'samples']\n",
    "df_metrics.columns = cols+ df_metrics.columns[6:].tolist()\n",
    "\n",
    "df_ = df_metrics[cols+['Leiden NMI', 'Leiden ARI', 'KMeans NMI', 'KMeans ARI', 'Silhouette label', 'cLISI', 'calinski_harabasz','davies_bouldin', 'Silhouette batch', 'iLISI',]]\n",
    "df_.to_csv(cfg['figures_dir'] + 'revision/separability_metrics.csv')\n",
    "df_metrics.to_csv(cfg['figures_dir'] + 'revision/separability_metrics_all_metrics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
